<!DOCTYPE html>
<HTML>
<!--#set var=TITLE value="TCW Summary" -->
<!--#include virtual="./ssi/head.html" -->
<!--#include virtual="./ssi/start1.html" -->
<a name=top>

Contents:
<ul>
<li><a href=#task>Programs</a>
<li><a href=#mach>Machines tested on</a>
<li><a href=#time>Timings</a>
<li><a href=#ref>References</a>
</ul>
<a name=task></a>
<h2>Programs</h2>
Select a program name to view the graphical interface of the Demo Project.
<p>
	<i>singleTCW contains four major programs:</i>
	<ol>
	<li><a href=img/runAS.png><code>runAS</code><a> -- annotation setup for input to <code>runSingleTCW</code>
	<ul>
	<li>Downloads the UniProt taxonomic and/or full SwissProt and TrEMBL .dat files
	<li>Create fasta files from .dat files for searching against TCW sequences
	<li>Download the GO mysql database and augment it with UniProt information about GO, KEGG, Pfam, and InterPro
	</ul>
	Note: <code>runSingleTCW</code> can take as input other databases such as Genbank nr, 
	but these results will not have associated GO annotations.
	<p>
	<li><a href=img/runSingleTCW.png><code>runSingleTCW</code></a> -- builds a single-species TCW database (sTCWdb)
	   <ul>
	   <li> Input: sequences and optional counts, where <i><b>any</b></i> of the following are valid (
	   the first three are NT-sTCWdbs and the last is a AA-sTCWdb):
		<ol>
		<li>Load RNA-seq transcripts and count data with optional replicates.
		<li>Load sequences with location information (e.g. predicted genes).
		<li>Assemble up to ~1M sequences, such as: transcript sets, 
		paired-end Sanger ESTs, or a mix of transcripts and ESTs. 
		<li>Load protein sequences and spectra (count) data with optional replicates.
		</ol>
	   <li> Annotation:
		<ol>
		<li>Annotate sequences with one or more nucleotide or protein databases (called annoDBs). 
		UniProt should be downloaded with the <code>runAS</code> program. The searching may be done with 
		the super-fast
		<code>DIAMOND</code> or the standard <code>BLAST</code>.
		<li>If UniProt is used, GO annotations along with EC, KEGG and Pfam identifiers are extracted 
		from the GO database and entered into the sTCWdb (The GO database is set up with the <code>runAS</code>).
		<li>Compute ORFS and GC content.
		</ol>
	   <li> All data and results are stored in a MySQL database. 
	   </ul>
	<br>		
	<li><a href=img/runDE.png><code>runDE</code></a> -- run Differential Expression analysis
	   <ul><li>An interface to several R packages (<code>EdgeR, DESeq</code>) for calculating differential
			of sequences. Additionally, it can execute a user-provided R script for DE calculation.
		<li>If the sTCWdb contains GOs, the <code>GOseq</code> R program can be used to compute differential GO terms.
	   </ul>
	<br>
	<li><a href=img/viewSingleTCW.png><code>viewSingleTCW</code></a> -- view a single-species TCW database
	   <ul><li>Query and view the results. There are various filters, for example,
	   filters are provided specific to taxonomic databases, trimmed GOs, filter by annotation, etc.
	   The initial view is the <a href=./stcw/tra.html>Overview</a>, which summarizes the results.
	   </ul>
	</ol>
	
	<i>multiTCW contains two major programs</i>:
	<ol>
	<li><a href=img/runMultiTCW.png><code>runMultiTCW</code></a> -- builds a multi-species comparison TCW database (mTCWdb)
		<ul><li>Builds a database from multiple sTCWdbs, which can be NT-sTCWdbs, AA-sTCWdbs
		or a mix. This has been tested with up to 5 input sTCWdbs.
		<li>Runs <code>DIAMOND</code> or <code>BLAST</code> to compare the sequences from the input TCWs. Add the resulting pairs to the database.
	 	<li>Clusters the pairs into ortholog groups. They can be clustered with 
	 	TCW Closure, TCW BBH (best bi-directional), TCW shared hit, <code>OrthoMCL</code>, and/or user-supplied clusters can be uploaded. 
		Multiple ortholog clustering can be in the database for query.
		<li>If the input is from two or more NT-sTCWdbs, coding statistics are calculated. Additionally,
		alignment files are output for input to <code>KaKs_calculator</code>, and the results of running
		the KaKs_calculator are input to <code>runMultiTCW</code>.
		<li>MSA (multiple sequence alignments) are computed for each cluster and scored with Trident.
	 	</ul>
	 <br>
	 <li><a href=img/viewMultiTCW.png><code>viewMultiTCW</code></a> -- view a multi-species TCW database
	 	<ul><li>Query and view the results. The results can be filtered on various attributes. A cluster
	 	can be viewed graphically with the results of <code>MAFFT</code> or <code>MUSCLE</code> 
	 	MSA or pairwise alignment
	 	(e.g. see graphical views <a href=img/viewMultiMSA.png>MSA</a> 
	 	and <a href=img/viewMultiPair.png>Pair</a>, respectively).
	 	</ul>
	</ol>
<hr>	
	<a name=mach></a>
<h2>Machines tested on</h2>

<table border=1 cellspacing=5 cellpadding=5>
<tr><th>OS<th>Architecture<th>Purchased<th>Database<th>Java<th>Test
<tr><td>Linux x86.64 (Centos 7) <td>3.2 Ghz AMD 24-Core, 128Gb<td>2011<td>MariaDB v10.4.12<td>v1.8<td>Build and View
<tr><td>Linux x86.64 (Centos 7)  <td>2.0 Ghz AMD 4-Core, 20Gb<td>2008<td>MariaDB v5.5.60<td>v1.7<td>View
<tr><td>MacOS (Catalina 10.15.4)<td>3.2 GHz Intel 6-Core i7, 64Gb<td>2020<td>MySQL v8.0.17<td>v14.0<td>Build and View
<tr><td>MacOS (Maverick 10.9.5) <td>2.4 Ghz Intel 2-Core i5, 16Gb<td>2012<td>MySQL v5.6.21<td>v1.7<td>View
</table>
<a name=time></a>
<h2>Timings</h2>

<h3>singleTCW</h3>
The timings were run on the MacOS (row #3) and Linux (row #1) of the above machine table.
The "Mb" numbers are maximum memory (when available), and are approximate.
	<table border=1 cellpadding=3>
	<tr><th>Task<th>Count<th colspan=2>Mac Mini<th colspan=2>Linux
	<tr><td>Load<td>64,930 seqs
		<td style="text-align:right">1m:26s
		<td style="text-align:right">20Mb
		<td style="text-align:right">2m:17s
		<td style="text-align:right">19Mb
	<tr><td>Instantiate<td>64,930 seqs
		<td style="text-align:right">47s
		<td style="text-align:right">4Mb
		<td style="text-align:right">1m:16s
		<td style="text-align:right">1Mb
	<tr><td>Diamond<sup>1</sup><td>5G-6G file size
		<td style="text-align:right">12m:09s
		<td style="text-align:right">---
		<td style="text-align:right">11m:54s
		<td style="text-align:right">---
	<tr><td>Annotate<sup>2</sup><td>461,118 unique hits
		<td style="text-align:right">18m:14s
		<td style="text-align:right">2374Mb
		<td style="text-align:right">56m:7s
		<td style="text-align:right">2384Mb
	<tr><td>ORF<td>64,930 ORFs
		<td style="text-align:right">3m:54s
		<td style="text-align:right">150Mb
		<td style="text-align:right">9m:36s
		<td style="text-align:right">246Mb
	<tr><td>GO<td>10,724 GOs
		<td style="text-align:right">28m:42s
		<td style="text-align:right">1030Mb
		<td style="text-align:right">52m:04s
		<td style="text-align:right">1350Mb
	</table>
	<small>
	<sup>1</sup>TR-plants; The May2020 file (5G) was used on Mac, 
	and the Oct2020 file (6G) was used on Linux, which influenced the increased times on Linux. 
	<br><sup>2</sup>SP-plants, TR-plants, SP-full; times do not include Diamond. Linux had 462,883 unique hits.
	</small>
	
	<h3>multiTCW</h3>
	Using the same two computers as above, the mTCW database was built from a dataset of 
	28,392 and another of 26,685 sequences. Both datasets were annotated with SP-plants, TR-plants, and SP-full,
	where the Mac versions were downloaded May2020 and the Linux on Oct2020.
	<table border=1 cellpadding=3>
	<tr><th>Task<th>Count<th colspan=2>Mac Mini<th colspan=2>Linux
	<tr><td>Build Database<td>55,077 seq and 595,698 unique hits<sup>1</sup>
	     <td style="text-align:right">&nbsp;6m:28s
	     <td style="text-align:right">150Mb
	     <td style="text-align:right">9m:31s
	     <td style="text-align:right">152Mb
	<tr><td>GO<td>21,693 GOs
	    <td style="text-align:right">16m:48s
	    <td style="text-align:right">11Mb
	    <td style="text-align:right">30m:26s
	    <td style="text-align:right">506Mb
	<tr><td>Add Pairs with Hits<td>392,919 AA and 43,485 NT pairs
	    <td style="text-align:right">5m:03s
	    <td style="text-align:right">61Mb
	    <td style="text-align:right">15m:54s  
	    <td style="text-align:right">68Mb
	<tr><td>Add 3 cluster sets<sup>2</sup><td>22,376 total clusters
		<td style="text-align:right">2m:56s
		<td style="text-align:right">33Mb
		<td style="text-align:right">8m:10s 
		<td style="text-align:right">31Mb
	<tr><td colspan=6><b>Run Stats</b>
	<tr><td>PCC<td>410,401 Pairs
		<td style="text-align:right">1m:32s
		<td style="text-align:right">68Mb
		<td style="text-align:right">2m:16s 
		<td style="text-align:right">63Mb
	<tr><td>Pair Stats<td>95,628 Pairs to align
		<td style="text-align:right">44m:33s
		<td style="text-align:right">624Mb
		<td style="text-align:right">2h:5m:19s 
		<td style="text-align:right">661Mb
	<tr><td>MSA<sup>3</sup> Stats<td>22,376 clusters
		<td style="text-align:right">1h:20m:11s
		<td style="text-align:right">---
		<td style="text-align:right">4h:34m:23s
		<td style="text-align:right">---
	</table>
	<small>
	<sup>1</sup>The Linux database had 606,845 unique hits.
	<br><sup>2</sup>The methods added were BBH, Closure and BestHit. Closure used the most memory.
	<br><sup>3</sup>This step uses the external program MAFFT.
	</small> 
	<p>The Linux times are much slower than the Mac, even though they comparable architectures; the Linux
	may not be optimized well and is a much older machine. It is important with MariaDB to make sure
	the variables are set right; execute 
	<tt>
	./runSingleTCW -v
	</tt>
	to print out some variables that seem to effect performance with MariaDB on Linux.
	<h3>Linux only for TCW v3.0</h3>
The following are from the supplement 1 of Soderlund (2019). There is not much speed difference between
TCW v3 and later versions.
<table border=1 cellpadding=3>
<tr><th>Program<th>Step<th>Time<th>Note
<tr><td>runAS<td>	Download and create UniProt FASTA files	<td style="text-align:right">5h:33m:24s           	<td>a
<tr><td>&nbsp;	<td>Download SwissProt and create subset FASTA file	<td style="text-align:right">4m:34s	<td>a
<tr><td>&nbsp;	<td>	Download and build GO database	<td style="text-align:right">8h:59m:55s	<td>b
<tr><td>runSingleTCW	<td>Build sTCW_rhi_NnR of 26,685 transcripts	<td style="text-align:right">3m:13s<td>	
<tr><td>&nbsp;	<td>	Annotate sequences	<td style="text-align:right">2h:15m:22s	<td>c
<tr><td>&nbsp;	<td>	ORF-finding	<td style="text-align:right">6m:09s	<td>
<tr><td>&nbsp;	<td>	Add GO annotations	<td style="text-align:right">50m:26s	<td>
<tr><td>runDE	<td>edgeR for 12 condition pairs	<td style="text-align:right">0m:20s	<td>d
<tr><td>&nbsp;	<td>	GOseq for each of the 12 DE results	<td style="text-align:right">10m:56s	<td>d
<tr><td>runMultiTCW	<td>Build mTCW_rhi of 198,702 transcripts	<td style="text-align:right">20m:56s	<td>
<tr><td>&nbsp;	<td>	Add GO annotation for 23,516 unique GOs	<td style="text-align:right">56m:02s	<td>
<tr><td>&nbsp;	<td>	Add 1,099,986 pairs after searching	<td style="text-align:right">28m:20s	<td>e
<tr><td>&nbsp;	<td>	Build Clusters (total)	<td style="text-align:right">22m:00s	<td>f
<tr><td>&nbsp;	<td>	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BBH (OlR-Os) 	<td style="text-align:right"> :04s	<td>
<tr><td>&nbsp;	<td>	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Closure 	<td style="text-align:right">:08s	<td>
<tr><td>&nbsp;	<td>	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;OrthoMCL	<td style="text-align:right">8m:04s	<td>
<tr><td>&nbsp;	<td>	Compute PCC for 1,099,986 pairs	<td style="text-align:right">3m:37s	<td>
<tr><td>&nbsp;	<td>	Pair-align and analyze 354,280 pairs	<td style="text-align:right">2h:27m:08s	<td>
<tr><td>&nbsp;	<td>	Multi-align and analyze 71,339 clusters	<td style="text-align:right">12h:14m:43s	<td>g
<tr><td>&nbsp;	<td>	Add KaKs values	<td style="text-align:right">1m:1s	<td>h
</table>
<small>
<br>a There can be considerable variation in download times.
<br>b The bulk of the time was from loading uniprot_trembl_bacterial.dat.gz, which took 6h:56m:58s; the compressed file was 57G and contained 96,592,456 entries. 
<br>c This did not include the DIAMOND formatting but did include the time for searching; the longest time for searching was against TrEMBL bacterial,  which took 35m:20s.
<br>d The time for executing the R code and loading the results.
<br>e The time does not include searching all sequences against themselves. The protein self-comparison took DIAMOND 3m22s and nucleotides self-search took Blastn 5m:13s.
<br>f The time for computing and adding all clusters; the majority of the time was for loading the clusters into the database. The following three individual cluster times are only for computing the clusters.
<br>g This includes the time to run MAFFT in parallel on each cluster.
<br>h This does not include the time to execute the KaKs_Calculator, which is run by the user before the add.
</small>
	<a name=ref></a>
	<h2>References</h2>
   	<table style="font-family:verdana,arial;font-size:13px;">
   		
    	<tr>
    		<td><i>Email: </i></td>
      		<td> tcw@agcol.arizona.edu</i></td>
		</tr>
    	<tr>
    		<td valign="top"><i>References: </i></td>
    	<td>
    	<br>C. Soderlund (2019) Transcriptome computational workbench (TCW): 
    	analysis of single and comparative transcriptomes. 
    	<a href="https://doi.org/10.1101/733311" class="ext" target="_blank">BioRxiv</a>.
    	<br><i>Describes the TCW v3 package.</i>
<br>&nbsp;
		<br>C. Soderlund, W. Nelson and S. Goff (2014)
		Allele Workbench: transcriptome pipeline and interactive graphics for allele-specific expression.
		PLOS ONE.
		<a href=http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0115740 class="ext" target="_blank">Link</a> 
		
		<br><i>Describes a pipeline that can be used with TCW, plus a new GO trim algorithm.</i>
		<br>&nbsp;
    	<br>C. Soderlund, W. Nelson, M. Willer and D. Gang (2013) TCW: Transcriptome Computational Workbench. PLOS ONE.
				<a href="http://dx.plos.org/10.1371/journal.pone.0069401" class="ext" target="_blank">Link</a>	
		<br><i>Describes the TCW v1 package.</i>
		<br>&nbsp;
    		<br>C. Soderlund, E. Johnson, M. Bomhoff, and A. Descour (2009) 
       		PAVE: Program for Assembling and Viewing ESTs. BMC Genomics.
<a href="http://www.biomedcentral.com/1471-2164/10/400" class="ext" target="_blank">Link </a>.
		<br><i>Describes the assembly algorithm.</i>
			</td>
		</tr>
	</table>
<br>
<p>
<!--#include virtual="./ssi/end.html" -->
</HTML>

